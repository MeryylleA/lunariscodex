# Lunaris Codex - Project Dependencies
# ------------------------------------
# This file lists the Python packages required to run and develop
# the Lunaris Codex project, including data preparation, training,
# inference, and utility scripts.
#
# Recommended Python version: 3.10.x or 3.11.x
#
# To install these dependencies into your virtual environment:
#   pip install --upgrade pip
#   pip install -r requirements.txt
#
# For GPU support (NVIDIA), ensure you have a compatible CUDA toolkit installed.
# The torch version listed here will attempt to install with CUDA support if available
# from PyPI's default wheels. For specific CUDA versions, consider installing
# PyTorch manually from pytorch.org.

# --- Core Deep Learning & ML Ecosystem ---
torch>=2.1.0               # PyTorch 2.1+ recommended for latest features (e.g., F.scaled_dot_product_attention, improved torch.compile).
                           # Tested with up to 2.3.x.

transformers>=4.35.0       # For AutoTokenizer, model utilities, etc. Newer versions often have better support.
datasets>=2.14.0           # For load_dataset and robust dataset handling.

# --- Data Handling & Utilities ---
numpy>=1.23.0              # Numerical operations, used for memmap arrays.
tqdm>=4.60.0               # Progress bars for data processing and training loops.
sentencepiece>=0.1.98      # Required by many tokenizers (e.g., Llama, StarCoder).
                           # Version 0.2.0 has been tested successfully.
safetensors>=0.4.0         # For secure and fast tensor serialization (used by Hugging Face, potentially for future model sharing).
                           # Note: Current training checkpoints use PyTorch's native .pt format.

# --- CLI Enhancement & User Experience ---
rich>=13.0.0               # For beautiful and informative command-line interfaces (used in inference.py).

# --- Optional for NVIDIA GPU Acceleration (Install Manually) ---
# flash-attn                 # For FlashAttention optimized attention mechanism.
                             # Not listed as a direct dependency to ensure CPU-only setup works out-of-the-box.
                             # If you have a compatible NVIDIA GPU and CUDA setup, install manually:
                             # pip install flash-attn --no-build-isolation
                             # Refer to the official flash-attn repository for specific version compatibility.

# --- Development & Testing ---
# pytest>=7.0.0              # For running unit tests.
# pytest-cov>=4.0.0          # For test coverage reporting.
# flake8>=6.0.0              # For Python style guide enforcement.
# black>=23.0.0              # For opinionated Python code formatting.
# isort>=5.10.0              # For sorting Python imports.
# clang-format               # For C++ code formatting (install via system package manager, e.g., apt-get).
