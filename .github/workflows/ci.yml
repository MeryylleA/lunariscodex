# .github/workflows/ci.yml
name: Lunaris Codex CI

on:
  push:
    branches: [ main ]
    paths: # For pushes to main, run if core files change
      - 'model.py'
      - 'prepare_data.py'
      - 'train.py'
      - 'inference.py'
      - 'text_cleaner/**'
      - 'data_analyzer/**'
      - 'bpe_trainer/**' 
      - 'tests/**'
      - 'Makefile'
      - 'requirements.txt'
      - '.github/workflows/ci.yml'
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review] 
    branches: [ main ]
    # No paths filter for PRs - handled per-job for better flexibility
  workflow_dispatch: 

env:
  # Global environment variables
  CXXFLAGS_MODE: RELEASE
  PYTHON_VERSION: '3.11'

jobs:
  # ==============================================================================
  # C++ UTILITIES BUILD & TEST JOB
  # ==============================================================================
  cpp_utilities:
    name: C++ Utilities Build & Test
    runs-on: ubuntu-latest
    outputs: 
      text_cleaner_exec: ${{ steps.executables.outputs.text_cleaner_exec }}
      data_analyzer_exec: ${{ steps.executables.outputs.data_analyzer_exec }}
      bpe_processor_exec: ${{ steps.executables.outputs.bpe_processor_exec }}

    steps:
      # --- Repository Setup ---
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Required for change detection

      # --- Change Detection ---
      - name: Detect C++ Related Changes
        id: changed_files
        uses: tj-actions/changed-files@v46
        with:
          files: |
            Makefile
            text_cleaner/**
            data_analyzer/**
            bpe_trainer/**
            model.py 
            prepare_data.py
            train.py
            inference.py
            requirements.txt 
            .github/workflows/ci.yml

      - name: Determine Job Execution
        id: should_run
        run: |
          if [[ "${{ steps.changed_files.outputs.any_changed }}" == "true" || \
                "${{ github.event_name }}" == "push" || \
                "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "value=true" >> $GITHUB_OUTPUT
            echo "‚úÖ C++ job will run: Changes detected or triggered by push/manual dispatch"
          else
            echo "value=false" >> $GITHUB_OUTPUT
            echo "‚è≠Ô∏è C++ job will be skipped: No relevant changes detected"
          fi

      # --- Build Environment Setup ---
      - name: Install Build Dependencies
        if: steps.should_run.outputs.value == 'true'
        run: |
          echo "üîß Installing C++ build dependencies..."
          sudo apt-get update -y
          sudo apt-get install -y nlohmann-json3-dev

      - name: Clean Previous Build Artifacts
        if: steps.should_run.outputs.value == 'true'
        run: |
          echo "üßπ Cleaning previous build artifacts..."
          make clean || echo "‚ÑπÔ∏è No previous artifacts to clean"

      # --- Build Cache Management ---
      - name: Cache C++ Executables
        if: steps.should_run.outputs.value == 'true'
        id: cache_executables
        uses: actions/cache@v4
        with:
          path: | 
            text_cleaner/lunaris_text_cleaner
            data_analyzer/lunaris_data_analyzer
            bpe_trainer/bpe_processor 
          key: ${{ runner.os }}-cpp-exec-${{ hashFiles('Makefile', 'text_cleaner/**/*.cpp', 'data_analyzer/**/*.cpp', 'bpe_trainer/**/*.cpp') }}
          restore-keys: |
            ${{ runner.os }}-cpp-exec-

      # --- Build Process ---
      - name: Build C++ Utilities
        if: steps.should_run.outputs.value == 'true' && steps.cache_executables.outputs.cache-hit != 'true'
        run: |
          echo "üî® Building C++ utilities..."
          make all CXXFLAGS_MODE=${{ env.CXXFLAGS_MODE }}
          echo "‚úÖ C++ utilities built successfully"

      - name: Set Executable Paths
        if: steps.should_run.outputs.value == 'true'
        id: executables
        run: |
          echo "text_cleaner_exec=text_cleaner/lunaris_text_cleaner" >> $GITHUB_OUTPUT
          echo "data_analyzer_exec=data_analyzer/lunaris_data_analyzer" >> $GITHUB_OUTPUT
          echo "bpe_processor_exec=bpe_trainer/bpe_processor" >> $GITHUB_OUTPUT
          
          if [[ "${{ steps.cache_executables.outputs.cache-hit }}" == "true" ]]; then
            echo "‚ôªÔ∏è C++ executables restored from cache"
          else
            echo "üÜï C++ executables built from source"
          fi

      # --- Text Cleaner Tests ---
      - name: Setup Text Cleaner Test Data
        if: steps.should_run.outputs.value == 'true'
        run: |
          echo "üìù Creating test data for Text Cleaner..."
          mkdir -p ./temp_text_cleaner_ci_input ./temp_text_cleaner_ci_output
          
          cat <<EOF > ./temp_text_cleaner_ci_input/sample_for_cleaner.txt
          <!DOCTYPE html>
          <html> <head><title>Test</title></head> <body>
          <!-- This is a comment -->
          <p>Hello   World!  </p>
          <script>alert("script content");</script>
          Another line.
          URL: http://example.com and email: test@example.com
          Duplicate Line
          Duplicate Line
          </body> </html>
          EOF

      - name: Test Text Cleaner Utility
        if: steps.should_run.outputs.value == 'true'
        run: |
          echo "üß™ Testing Text Cleaner utility..."
          TEXT_CLEANER_EXEC="./${{ steps.executables.outputs.text_cleaner_exec }}"
          
          # Verify executable exists
          if [ ! -f "$TEXT_CLEANER_EXEC" ]; then 
            echo "‚ùå ERROR: Text Cleaner executable not found at: $TEXT_CLEANER_EXEC"
            exit 1
          fi
          
          # Run text cleaner
          "$TEXT_CLEANER_EXEC" \
            --input ./temp_text_cleaner_ci_input/sample_for_cleaner.txt \
            --output ./temp_text_cleaner_ci_output/cleaned_sample.txt \
            --remove-html --normalize-whitespace --remove-empty-lines \
            --to-lowercase \
            --process-urls --url-placeholder "[url]" \
            --process-emails --email-placeholder "[email]" \
            --remove-exact-duplicates || {
              echo "‚ùå Text Cleaner execution failed"
              exit 1
            }
          
          # Create expected output for comparison
          cat <<-EXPECTED_EOF > expected_output_tc.txt
          test
          hello world!
          another line.
          url: [url] and email: [email]
          duplicate line
          EXPECTED_EOF
          
          # Compare outputs
          echo "üìä Comparing actual vs expected output..."
          if diff -u expected_output_tc.txt ./temp_text_cleaner_ci_output/cleaned_sample.txt; then
            echo "‚úÖ Text Cleaner output matches expected content"
          else
            echo "‚ùå Text Cleaner output does NOT match expected content"
            exit 1
          fi

      # --- BPE Processor Tests ---
      - name: Setup BPE Processor Test Data
        if: steps.should_run.outputs.value == 'true'
        run: |
          echo "üìù Creating test corpus for BPE Processor..."
          mkdir -p ./temp_bpe_ci/corpus ./temp_bpe_ci/model_output
          
          cat <<EOF > ./temp_bpe_ci/corpus/corpus.txt
          hello world this is a test a test
          another line for another test of the bpe
          hello world again
          EOF

      - name: Test BPE Processor Training
        if: steps.should_run.outputs.value == 'true'
        id: bpe_train
        run: |
          echo "üß™ Testing BPE Processor training..."
          BPE_EXEC="./${{ steps.executables.outputs.bpe_processor_exec }}"
          
          # Verify executable exists
          if [ ! -f "$BPE_EXEC" ]; then 
            echo "‚ùå ERROR: BPE Processor executable not found at: $BPE_EXEC"
            exit 1
          fi
          
          # Train BPE model
          "$BPE_EXEC" \
            --action train \
            --corpus ./temp_bpe_ci/corpus/corpus.txt \
            --vocab-size 270 \
            --output ./temp_bpe_ci/model_output/ci_bpe_model/ \
            --mode byte --verbose || {
              echo "‚ùå BPE Processor training failed"
              exit 1
            }
            
          # Verify output files were created
          REQUIRED_FILES=(
            "./temp_bpe_ci/model_output/ci_bpe_model/bpe_model_lunaris.json"
            "./temp_bpe_ci/model_output/ci_bpe_model/merges_lunaris.txt"
            "./temp_bpe_ci/model_output/ci_bpe_model/vocabulary_lunaris.txt"
          )
          
          for file in "${REQUIRED_FILES[@]}"; do
            if [ ! -f "$file" ]; then
              echo "‚ùå ERROR: Required output file not found: $file"
              ls -R ./temp_bpe_ci/model_output/
              exit 1
            fi
          done
          
          echo "‚úÖ BPE Processor training completed successfully"

      - name: Test BPE Processor Tokenization
        if: steps.should_run.outputs.value == 'true' && success() && steps.bpe_train.outcome == 'success'
        run: |
          echo "üß™ Testing BPE Processor tokenization..."
          BPE_EXEC="./${{ steps.executables.outputs.bpe_processor_exec }}"
          MODEL_PATH="./temp_bpe_ci/model_output/ci_bpe_model/" 
          INPUT_TEXT="hello test world"
          
          echo "Input text: '$INPUT_TEXT'"
          
          # Run tokenization
          TOKEN_IDS_OUTPUT=$("$BPE_EXEC" --action tokenize --model_path "$MODEL_PATH" --input_text "$INPUT_TEXT" --verbose)
          
          if [ $? -ne 0 ]; then
            echo "‚ùå ERROR: BPE Processor tokenization failed"
            echo "Output: $TOKEN_IDS_OUTPUT"
            exit 1
          fi
          
          # Validate output
          if [ -z "$TOKEN_IDS_OUTPUT" ]; then
            echo "‚ùå ERROR: Empty tokenization output for non-empty input"
            exit 1
          fi
          
          if ! echo "$TOKEN_IDS_OUTPUT" | grep -qE '[0-9]+'; then
            echo "‚ùå ERROR: Output doesn't contain token IDs: $TOKEN_IDS_OUTPUT"
            exit 1
          fi
          
          echo "‚úÖ BPE Processor tokenization successful"
          echo "Token IDs (first 50 chars): ${TOKEN_IDS_OUTPUT:0:50}..."

      # --- Job Completion Handling ---
      - name: Skip C++ Job (No Changes)
        if: steps.should_run.outputs.value == 'false'
        run: |
          echo "‚è≠Ô∏è Skipping C++ utilities job - no relevant changes detected in this PR"

      - name: Cleanup and Error Reporting
        if: always()
        run: |
          # Post failure comment for PRs
          if [[ "${{ job.status }}" == "failure" && \
                "${{ steps.should_run.outputs.value }}" == "true" && \
                "${{ github.event_name }}" == "pull_request" ]]; then
            
            echo "::group::Posting C++ Job Failure Comment"
            read -r -d '' COMMENT_BODY <<EOF
          ---
          **Lunaris Codex CI Status: FAILED ‚ùå** 
          Workflow: \`${{ github.workflow }}\`
          Job: \`${{ job.name }}\` (C++ Utilities)
          Branch: \`${{ github.head_ref }}\` (Commit: \`${{ github.sha }}\`)

          C++ utility tests have failed. Please review the build logs and fix any issues.
          ‚û°Ô∏è [View Action Logs](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})

          *This is an automated message from your Lunaris Codex CI system.*
          EOF
            
            gh issue comment ${{ github.event.pull_request.number }} \
              --repo ${{ github.repository }} \
              --body "$COMMENT_BODY" || echo "‚ö†Ô∏è Failed to post failure comment"
            echo "::endgroup::"
          fi
          
          # Cleanup temporary files
          echo "üßπ Cleaning up temporary test files..."
          rm -rf ./temp_text_cleaner_ci_input ./temp_text_cleaner_ci_output \
                 ./expected_output_tc.txt ./temp_bpe_ci
          echo "‚úÖ Cleanup completed"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # ==============================================================================
  # PYTHON SUITE TEST JOB
  # ==============================================================================
  python_suite:
    name: Python Suite Tests
    runs-on: ubuntu-latest

    steps:
      # --- Repository Setup ---
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Required for change detection

      # --- Change Detection ---
      - name: Detect Python Related Changes
        id: changed_files
        uses: tj-actions/changed-files@v46
        with:
          files: |
            model.py
            prepare_data.py
            train.py
            inference.py
            tests/**
            requirements.txt
            .github/workflows/ci.yml

      - name: Determine Job Execution
        id: should_run
        run: |
          if [[ "${{ steps.changed_files.outputs.any_changed }}" == "true" || \
                "${{ github.event_name }}" == "push" || \
                "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "value=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Python job will run: Changes detected or triggered by push/manual dispatch"
          else
            echo "value=false" >> $GITHUB_OUTPUT
            echo "‚è≠Ô∏è Python job will be skipped: No relevant changes detected"
          fi

      # --- Python Environment Setup ---
      - name: Setup Python Environment
        if: steps.should_run.outputs.value == 'true'
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache Python Dependencies
        id: cache_python_deps
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install Python Dependencies
        if: steps.should_run.outputs.value == 'true'
        run: |
          echo "üì¶ Installing Python dependencies..."
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          echo "‚úÖ Dependencies installed successfully"

      # --- Python Unit Tests ---
      - name: Run Model Unit Tests
        if: steps.should_run.outputs.value == 'true'
        run: |
          echo "üß™ Running model unit tests with pytest..."
          export PYTHONPATH=$PYTHONPATH:$(pwd)
          pytest tests/ -k "test_model" \
            --cov=model \
            --cov-report=xml \
            --cov-report=term-missing
          echo "‚úÖ Model tests completed"

      - name: Upload Coverage Report
        if: steps.should_run.outputs.value == 'true' && success()
        uses: codecov/codecov-action@v5 
        with:
          token: ${{ secrets.CODECOV_TOKEN }} 
          files: ./coverage.xml 
          flags: model-tests

      # --- Integration Tests Setup ---
      - name: Create Test Datasets
        if: steps.should_run.outputs.value == 'true'
        run: |
          echo "üìù Creating dummy datasets for integration tests..."
          
          # Training data
          mkdir -p ./temp_data_ci_train
          echo "def train_function_one(): return 'train1'" > ./temp_data_ci_train/train_sample_1.py
          echo "class TrainSampleClass:\n  value = 'train2'" > ./temp_data_ci_train/train_sample_2.py
          
          # Validation data
          mkdir -p ./temp_data_ci_val
          echo "def validation_function(): return 'validation_data_here'" > ./temp_data_ci_val/val_sample_1.py
          echo "# Another validation line" > ./temp_data_ci_val/val_sample_2.py
          
          echo "‚úÖ Test datasets created"

      # --- Data Preparation Tests ---
      - name: Test Data Preparation Script
        if: steps.should_run.outputs.value == 'true'
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          echo "üîÑ Testing data preparation script..."
          
          # Prepare training data
          python prepare_data.py \
            --data_source_type text_file_lines \
            --dataset_name_or_path "./temp_data_ci_train/*.py" \
            --tokenizer_name_or_path gpt2 \
            --output_path ./processed_data_ci/ci_train_data.memmap \
            --max_length 32 --max_examples 2 --overwrite_output

          # Prepare validation data
          python prepare_data.py \
            --data_source_type text_file_lines \
            --dataset_name_or_path "./temp_data_ci_val/*.py" \
            --tokenizer_name_or_path gpt2 \
            --output_path ./processed_data_ci/ci_val_data.memmap \
            --max_length 32 --max_examples 2 --overwrite_output
          
          echo "‚úÖ Data preparation completed"

      # --- Training Tests ---
      - name: Test Training Script
        if: steps.should_run.outputs.value == 'true'
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          echo "üèãÔ∏è Testing training script with toy model..."
          python train.py \
            --memmap_file_train ./processed_data_ci/ci_train_data.memmap \
            --num_sequences_train 2 \
            --memmap_file_val ./processed_data_ci/ci_val_data.memmap \
            --num_sequences_val 2 \
            --tokenizer_name_or_path gpt2 \
            --dataset_max_length 32 --dataset_dtype int32 \
            --model_max_seq_len 32 --d_model 32 --n_layers 1 --n_heads 1 \
            --batch_size 1 --num_epochs 1 --device cpu \
            --checkpoint_dir ./checkpoints_ci \
            --log_interval 1 --save_strategy epoch \
            --lora_rank 0 --seed 42
          echo "‚úÖ Training completed"

      - name: Verify Training Outputs
        if: steps.should_run.outputs.value == 'true' && success()
        id: verify_checkpoints
        run: |
          echo "üîç Verifying training checkpoint files..."
          echo "Checkpoint directory contents:"
          ls -R ./checkpoints_ci
          
          # Check for expected files
          MAIN_CKPT_PATTERN="./checkpoints_ci/lunaris_codex_epoch-1_step-*.pt" 
          BEST_MODEL_FILE="./checkpoints_ci/best_model.pt"
          
          if ! ls $MAIN_CKPT_PATTERN 1> /dev/null 2>&1; then 
            echo "‚ùå ERROR: Main checkpoint file not found (pattern: $MAIN_CKPT_PATTERN)"
            exit 1
          fi
          
          if [ ! -f "$BEST_MODEL_FILE" ]; then 
            echo "‚ùå ERROR: Best model checkpoint not found: $BEST_MODEL_FILE"
            exit 1
          fi
          
          echo "‚úÖ All expected checkpoint files found"

      # --- Inference Tests ---
      - name: Test Inference Script
        if: steps.should_run.outputs.value == 'true' && success() && steps.verify_checkpoints.outcome == 'success'
        run: |
          echo "üîÆ Testing inference script..."
          CHECKPOINT_PATH="./checkpoints_ci/best_model.pt"
          
          OUTPUT=$(python inference.py \
            --checkpoint_path "$CHECKPOINT_PATH" \
            --tokenizer_name_or_path gpt2 \
            --prompt "Test prompt:" \
            --max_new_tokens 5 \
            --temperature 0.5 \
            --device cpu --no_color)
          
          if [ $? -eq 0 ] && [ -n "$OUTPUT" ]; then
            echo "‚úÖ Inference script executed successfully"
            echo "Generated output (first 100 chars): ${OUTPUT:0:100}..."
          else
            echo "‚ùå ERROR: Inference script failed or produced no output"
            echo "Output: $OUTPUT" 
            exit 1
          fi

      # --- Job Completion Handling ---
      - name: Skip Python Job (No Changes)
        if: steps.should_run.outputs.value == 'false'
        run: |
          echo "‚è≠Ô∏è Skipping Python suite job - no relevant changes detected in this PR"

      - name: Cleanup and Error Reporting
        if: always()
        run: |
          # Post failure comment for PRs
          if [[ "${{ job.status }}" == "failure" && \
                "${{ steps.should_run.outputs.value }}" == "true" && \
                "${{ github.event_name }}" == "pull_request" ]]; then
            
            echo "::group::Posting Python Job Failure Comment"
            read -r -d '' COMMENT_BODY <<EOF
          ---
          **Lunaris Codex CI Status: FAILED ‚ùå** 
          Workflow: \`${{ github.workflow }}\`
          Job: \`${{ job.name }}\` (Python Suite)
          Branch: \`${{ github.head_ref }}\` (Commit: \`${{ github.sha }}\`)

          Python suite tests have failed. Please review the test logs and fix any issues.
          ‚û°Ô∏è [View Action Logs](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})

          *This is an automated message from your Lunaris Codex CI system.*
          EOF
            
            gh issue comment ${{ github.event.pull_request.number }} \
              --repo ${{ github.repository }} \
              --body "$COMMENT_BODY" || echo "‚ö†Ô∏è Failed to post failure comment"
            echo "::endgroup::"
          fi
          
          # Cleanup temporary files
          echo "üßπ Cleaning up temporary test files..."
          rm -rf ./temp_data_ci_train ./temp_data_ci_val \
                 ./processed_data_ci ./checkpoints_ci \
                 ./coverage.xml
          echo "‚úÖ Cleanup completed"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
