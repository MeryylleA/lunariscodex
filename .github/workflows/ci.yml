# .github/workflows/ci.yml
name: Lunaris Codex CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  test-pipeline:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache Python dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install Python dependencies
        run: |
          python -m venv .venv-ci
          source .venv-ci/bin/activate
          pip install --upgrade pip
          pip install -r requirements.txt
      
      # --- Text Cleaner Test Setup ---
      - name: Create dummy text file for Text Cleaner CI
        run: |
          mkdir -p ./temp_text_cleaner_ci_input
          cat <<EOF > ./temp_text_cleaner_ci_input/sample_for_cleaner.txt
          <!DOCTYPE html>
          <html> <head><title>Test</title></head> <body>
          <!-- This is a comment -->
          <p>Hello   World!  </p>
          <script>alert("script content");</script>
          Another line.
          URL: http://example.com and email: test@example.com
          Duplicate Line
          Duplicate Line
          </body> </html>
          EOF
          mkdir -p ./temp_text_cleaner_ci_output

      # --- Cache and Build Text Cleaner ---
      - name: Cache C++ build for Text Cleaner
        id: cache-text-cleaner # Added id for explicit check later
        uses: actions/cache@v3
        with:
          path: ./text_cleaner/lunaris_text_cleaner_ci_executable # Cache executable in its dir
          key: ${{ runner.os }}-text-cleaner-${{ hashFiles('text_cleaner/lunaris_text_cleaner.cpp') }}
          restore-keys: |
            ${{ runner.os }}-text-cleaner-

      - name: Build C++ Text Cleaner
        if: steps.cache-text-cleaner.outputs.cache-hit != 'true' # Only build if not cached
        run: |
          echo "Building Text Cleaner..."
          cd text_cleaner
          g++ lunaris_text_cleaner.cpp -o lunaris_text_cleaner_ci_executable -std=c++17 -O2 || { echo "Text Cleaner compilation failed"; exit 1; }
          cd ..
        # else: # Optional: print message if using cache
        #   echo "Using cached Text Cleaner executable."

      # --- Run and Test Text Cleaner ---
      - name: Run and Test C++ Text Cleaner
        run: | # Use o literal block scalar aqui
          # Ensure executable exists (either from cache or build)
          if [ ! -f ./text_cleaner/lunaris_text_cleaner_ci_executable ]; then
            echo "ERROR: Text Cleaner executable not found after cache/build step!"
            exit 1
          fi

          ./text_cleaner/lunaris_text_cleaner_ci_executable \
            --input ./temp_text_cleaner_ci_input/sample_for_cleaner.txt \
            --output ./temp_text_cleaner_ci_output/cleaned_sample.txt \
            --remove-html \
            --normalize-whitespace \
            --remove-empty-lines \
            --to-lowercase \
            --process-urls --url-placeholder "[URL]" \
            --process-emails --email-placeholder "[EMAIL]" \
            --remove-exact-duplicates || { echo "Text Cleaner execution failed"; exit 1; }

          echo "--- Cleaned Text Cleaner Output ---"
          ACTUAL_OUTPUT_FILE="./temp_text_cleaner_ci_output/cleaned_sample.txt"
          cat "$ACTUAL_OUTPUT_FILE"
          
          # Define expected output
          read -r -d '' EXPECTED_CONTENT <<EOF
          test
          hello world!
          another line.
          url: [url] and email: [email]
          duplicate line
          EOF

          # Normalize actual output for comparison
          # Remove linhas completamente vazias e \r
          NORMALIZED_ACTUAL_CONTENT=$(awk 'NF' "$ACTUAL_OUTPUT_FILE" | tr -d '\r')
          
          # Normalize expected content
          NORMALIZED_EXPECTED_CONTENT=$(echo "$EXPECTED_CONTENT" | awk 'NF' | tr -d '\r')

          echo "--- Comparing Content ---"
          echo "Normalized Expected:"
          echo "$NORMALIZED_EXPECTED_CONTENT"
          echo "Normalized Actual:"
          echo "$NORMALIZED_ACTUAL_CONTENT"
          echo "-----------------------"

          if [ "$NORMALIZED_ACTUAL_CONTENT" = "$NORMALIZED_EXPECTED_CONTENT" ]; then
            echo "Text Cleaner output matches expected content."
          else
            echo "ERROR: Text Cleaner output does NOT match expected content."
            # Para um diff melhor no log do CI, podemos usar o comando diff
            echo "Diff:"
            # Criar arquivos temporários para diff é mais confiável
            echo "$EXPECTED_CONTENT" > expected.txt
            # O ACTUAL_CONTENT para diff deve ser o não normalizado para refletir o arquivo real
            diff -u expected.txt "$ACTUAL_OUTPUT_FILE" || true # o '|| true' evita que o diff falhe o script se houver diferenças
            rm expected.txt
            exit 1
          fi

      # --- Python Data Prep (Original Steps) ---
      - name: Create dummy datasets for Python CI
        run: |
          mkdir -p ./temp_data_ci_train
          echo "def train_function_one(): return 'train1'" > ./temp_data_ci_train/train_sample_1.py
          echo "class TrainSampleClass:\n  value = 'train2'" > ./temp_data_ci_train/train_sample_2.py
          mkdir -p ./temp_data_ci_val
          echo "def validation_function(): return 'validation_data_here'" > ./temp_data_ci_val/val_sample_1.py
          echo "# Another validation line" > ./temp_data_ci_val/val_sample_2.py

      - name: Run prepare_data.py for CI datasets
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          source .venv-ci/bin/activate
          echo "--- Preparing Training Data for CI ---"
          python prepare_data.py \
            --data_source_type text_file_lines \
            --dataset_name_or_path "./temp_data_ci_train/*.py" \
            --tokenizer_name_or_path gpt2 \
            --max_length 32 \
            --output_path ./processed_data_ci/ci_train_data.memmap \
            --max_examples 2

          echo "--- Preparing Validation Data for CI ---"
          python prepare_data.py \
            --data_source_type text_file_lines \
            --dataset_name_or_path "./temp_data_ci_val/*.py" \
            --tokenizer_name_or_path gpt2 \
            --max_length 32 \
            --output_path ./processed_data_ci/ci_val_data.memmap \
            --max_examples 2

      # --- Data Analyzer (Original Steps) ---
      - name: Cache C++ build for Data Analyzer
        id: cache-data-analyzer # Added id for explicit check later
        uses: actions/cache@v3
        with:
          path: ./data_analyzer/lda_ci_executable 
          key: ${{ runner.os }}-data-analyzer-${{ hashFiles('data_analyzer/lunaris_data_analyzer.cpp') }}
          restore-keys: |
            ${{ runner.os }}-data-analyzer-

      - name: Build and Test C++ data analyzer
        run: |
          if [ ! -f ./data_analyzer/lda_ci_executable ]; then # Check if file exists (cache might have created it)
             # Also check if cache-hit was false if you want to be very explicit, 
             # but checking file existence is often enough.
            echo "Building Data Analyzer..."
            cd data_analyzer
            g++ lunaris_data_analyzer.cpp -o lda_ci_executable -std=c++17 -O2 || { echo "Data Analyzer compilation failed"; exit 1; }
            cd ..
          else
            echo "Using cached Data Analyzer executable or already built."
          fi
          
          # Ensure executable exists
          if [ ! -f ./data_analyzer/lda_ci_executable ]; then
            echo "ERROR: Data Analyzer executable not found after cache/build step!"
            exit 1
          fi

          DATA_ANALYZER_CMD="./data_analyzer/lda_ci_executable \
            --file ./processed_data_ci/ci_train_data.memmap \
            --num_sequences 2 \
            --max_length 32 \
            --dtype int32 \
            --print_seq 1 \
            --top_n_tokens 3"
          
          echo "Executing command: $DATA_ANALYZER_CMD"
          # Using bash -c to handle the command string, safer than eval
          bash -c "$DATA_ANALYZER_CMD" || { echo "Analyzer execution failed"; exit 1; }

      # --- Python Training (Original Steps) ---
      - name: Run train.py (toy model with validation)
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          source .venv-ci/bin/activate
          python train.py \
            --memmap_file_train ./processed_data_ci/ci_train_data.memmap \
            --num_sequences_train 2 \
            --memmap_file_val ./processed_data_ci/ci_val_data.memmap \
            --num_sequences_val 2 \
            --tokenizer_name_or_path gpt2 \
            --dataset_max_length 32 \
            --dataset_dtype int32 \
            --model_max_seq_len 32 \
            --d_model 32 \
            --n_layers 1 \
            --n_heads 1 \
            --batch_size 1 \
            --num_epochs 1 \
            --device cpu \
            --checkpoint_dir ./checkpoints_ci \
            --log_interval 1 \
            --save_strategy epoch \
            --lora_rank 0 \
            --seed 42

      - name: Check for checkpoint files
        run: |
          echo "Listing contents of checkpoint directory: ./checkpoints_ci"
          ls -R ./checkpoints_ci
          
          MAIN_CKPT_FILE="./checkpoints_ci/lunaris_codex_epoch-1_step-2.pt"
          BEST_MODEL_FILE="./checkpoints_ci/best_model.pt"

          if [ ! -f "$MAIN_CKPT_FILE" ]; then
            echo "ERROR: Main checkpoint file '$MAIN_CKPT_FILE' not found!"
            exit 1
          fi
          if [ ! -f "$BEST_MODEL_FILE" ]; then
            echo "ERROR: 'best_model.pt' not found!"
            exit 1
          fi
          echo "All expected checkpoint files found. CI test successful."

      - name: Clean up
        if: always()
        run: |
          rm -rf .venv-ci \
                 ./temp_data_ci_train ./temp_data_ci_val \
                 ./processed_data_ci ./checkpoints_ci \
                 ./data_analyzer/lda_ci_executable \
                 ./temp_text_cleaner_ci_input ./temp_text_cleaner_ci_output \
                 ./text_cleaner/lunaris_text_cleaner_ci_executable # Added text cleaner artifacts
          echo "Cleaned up temporary files and directories."
