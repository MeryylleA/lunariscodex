# .github/workflows/ci.yml
name: Lunaris Codex CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  test-pipeline:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache Python dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install Python dependencies
        run: |
          python -m venv .venv-ci
          source .venv-ci/bin/activate
          pip install --upgrade pip
          pip install -r requirements.txt
      
      # --- Text Cleaner Test Setup ---
      - name: Create dummy text file for Text Cleaner CI
        run: |
          mkdir -p ./temp_text_cleaner_ci_input
          # This is the input text the cleaner will process
          cat <<EOF > ./temp_text_cleaner_ci_input/sample_for_cleaner.txt
          <!DOCTYPE html>
          <html> <head><title>Test</title></head> <body>
          <!-- This is a comment -->
          <p>Hello   World!  </p>
          <script>alert("script content");</script>
          Another line.
          URL: http://example.com and email: test@example.com
          Duplicate Line
          Duplicate Line
          </body> </html>
          EOF
          mkdir -p ./temp_text_cleaner_ci_output

      # --- Cache and Build Text Cleaner ---
      - name: Cache C++ build for Text Cleaner
        id: cache-text-cleaner
        uses: actions/cache@v3
        with:
          path: ./text_cleaner/lunaris_text_cleaner_ci_executable
          key: ${{ runner.os }}-text-cleaner-${{ hashFiles('text_cleaner/lunaris_text_cleaner.cpp') }}
          restore-keys: |
            ${{ runner.os }}-text-cleaner-

      - name: Build C++ Text Cleaner
        if: steps.cache-text-cleaner.outputs.cache-hit != 'true'
        run: |
          echo "Building Text Cleaner..."
          cd text_cleaner
          g++ lunaris_text_cleaner.cpp -o lunaris_text_cleaner_ci_executable -std=c++17 -O2 || { echo "Text Cleaner compilation failed"; exit 1; }
          cd ..
      
      # --- Run and Test Text Cleaner ---
      - name: Run and Test C++ Text Cleaner
        run: |
          # Ensure executable exists
          if [ ! -f ./text_cleaner/lunaris_text_cleaner_ci_executable ]; then
            echo "ERROR: Text Cleaner executable not found after cache/build step!"
            exit 1
          fi

          # Run the cleaner
          ./text_cleaner/lunaris_text_cleaner_ci_executable \
            --input ./temp_text_cleaner_ci_input/sample_for_cleaner.txt \
            --output ./temp_text_cleaner_ci_output/cleaned_sample.txt \
            --remove-html \
            --normalize-whitespace \
            --remove-empty-lines \
            --to-lowercase \
            --process-urls --url-placeholder "[url]" \
            --process-emails --email-placeholder "[email]" \
            --remove-exact-duplicates || { echo "Text Cleaner execution failed"; exit 1; }

          echo "--- Cleaned Text Cleaner Output (from file) ---"
          ACTUAL_OUTPUT_FILE="./temp_text_cleaner_ci_output/cleaned_sample.txt"
          cat "$ACTUAL_OUTPUT_FILE"
          echo "--- End of Actual Output ---"
          
          # Define expected output using a here-string which is less prone to indent issues
          # Make sure there are NO leading spaces on these lines in your YAML
          # unless they are genuinely part of the expected output.
          # Using <<-EOF allows leading tabs in the here-document to be stripped, but not spaces.
          # So ensure no leading spaces.
          cat <<-EXPECTED_EOF > expected_output.txt
          test
          hello world!
          another line.
          url: [url] and email: [email]
          duplicate line
          EXPECTED_EOF
          # The final newline from the last line of EXPECTED_EOF is preserved.
          # If your tool's output does not have a final newline on the last line of content,
          # you might need to adjust this or the comparison.

          echo "--- Expected Output (from here-doc) ---"
          cat expected_output.txt
          echo "--- End of Expected Output ---"

          # Compare the actual output file with the expected output file
          # The `diff` command will exit with 0 if files are same, non-zero otherwise.
          # `-a` treats files as text. `-u` for unified diff format.
          echo "Comparing files..."
          if diff -a -u expected_output.txt "$ACTUAL_OUTPUT_FILE"; then
            echo "Text Cleaner output matches expected content."
          else
            echo "ERROR: Text Cleaner output does NOT match expected content. Diff shown above."
            # The diff output itself will indicate the differences.
            exit 1
          fi
          rm expected_output.txt

      # --- Python Data Prep (Original Steps) ---
      - name: Create dummy datasets for Python CI
        run: |
          mkdir -p ./temp_data_ci_train
          echo "def train_function_one(): return 'train1'" > ./temp_data_ci_train/train_sample_1.py
          echo "class TrainSampleClass:\n  value = 'train2'" > ./temp_data_ci_train/train_sample_2.py
          mkdir -p ./temp_data_ci_val
          echo "def validation_function(): return 'validation_data_here'" > ./temp_data_ci_val/val_sample_1.py
          echo "# Another validation line" > ./temp_data_ci_val/val_sample_2.py

      - name: Run prepare_data.py for CI datasets
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          source .venv-ci/bin/activate
          echo "--- Preparing Training Data for CI ---"
          python prepare_data.py \
            --data_source_type text_file_lines \
            --dataset_name_or_path "./temp_data_ci_train/*.py" \
            --tokenizer_name_or_path gpt2 \
            --max_length 32 \
            --output_path ./processed_data_ci/ci_train_data.memmap \
            --max_examples 2

          echo "--- Preparing Validation Data for CI ---"
          python prepare_data.py \
            --data_source_type text_file_lines \
            --dataset_name_or_path "./temp_data_ci_val/*.py" \
            --tokenizer_name_or_path gpt2 \
            --max_length 32 \
            --output_path ./processed_data_ci/ci_val_data.memmap \
            --max_examples 2

      # --- Data Analyzer (Original Steps) ---
      - name: Cache C++ build for Data Analyzer
        id: cache-data-analyzer
        uses: actions/cache@v3
        with:
          path: ./data_analyzer/lda_ci_executable 
          key: ${{ runner.os }}-data-analyzer-${{ hashFiles('data_analyzer/lunaris_data_analyzer.cpp') }}
          restore-keys: |
            ${{ runner.os }}-data-analyzer-

      - name: Build and Test C++ data analyzer
        run: |
          if [ ! -f ./data_analyzer/lda_ci_executable ]; then
            echo "Building Data Analyzer..."
            cd data_analyzer
            g++ lunaris_data_analyzer.cpp -o lda_ci_executable -std=c++17 -O2 || { echo "Data Analyzer compilation failed"; exit 1; }
            cd ..
          else
            echo "Using cached Data Analyzer executable or already built."
          fi
          
          if [ ! -f ./data_analyzer/lda_ci_executable ]; then
            echo "ERROR: Data Analyzer executable not found after cache/build step!"
            exit 1
          fi

          DATA_ANALYZER_CMD="./data_analyzer/lda_ci_executable \
            --file ./processed_data_ci/ci_train_data.memmap \
            --num_sequences 2 \
            --max_length 32 \
            --dtype int32 \
            --print_seq 1 \
            --top_n_tokens 3"
          
          echo "Executing command: $DATA_ANALYZER_CMD"
          bash -c "$DATA_ANALYZER_CMD" || { echo "Analyzer execution failed"; exit 1; }

      # --- Python Training (Original Steps) ---
      - name: Run train.py (toy model with validation)
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          source .venv-ci/bin/activate
          python train.py \
            --memmap_file_train ./processed_data_ci/ci_train_data.memmap \
            --num_sequences_train 2 \
            --memmap_file_val ./processed_data_ci/ci_val_data.memmap \
            --num_sequences_val 2 \
            --tokenizer_name_or_path gpt2 \
            --dataset_max_length 32 \
            --dataset_dtype int32 \
            --model_max_seq_len 32 \
            --d_model 32 \
            --n_layers 1 \
            --n_heads 1 \
            --batch_size 1 \
            --num_epochs 1 \
            --device cpu \
            --checkpoint_dir ./checkpoints_ci \
            --log_interval 1 \
            --save_strategy epoch \
            --lora_rank 0 \
            --seed 42

      - name: Check for checkpoint files
        run: |
          echo "Listing contents of checkpoint directory: ./checkpoints_ci"
          ls -R ./checkpoints_ci
          
          MAIN_CKPT_FILE="./checkpoints_ci/lunaris_codex_epoch-1_step-2.pt"
          BEST_MODEL_FILE="./checkpoints_ci/best_model.pt"

          if [ ! -f "$MAIN_CKPT_FILE" ]; then
            echo "ERROR: Main checkpoint file '$MAIN_CKPT_FILE' not found!"
            exit 1
          fi
          if [ ! -f "$BEST_MODEL_FILE" ]; then
            echo "ERROR: 'best_model.pt' not found!"
            exit 1
          fi
          echo "All expected checkpoint files found. CI test successful."

      - name: Clean up
        if: always()
        run: |
          rm -rf .venv-ci \
                 ./temp_data_ci_train ./temp_data_ci_val \
                 ./processed_data_ci ./checkpoints_ci \
                 ./data_analyzer/lda_ci_executable \
                 ./temp_text_cleaner_ci_input ./temp_text_cleaner_ci_output \
                 ./text_cleaner/lunaris_text_cleaner_ci_executable
          echo "Cleaned up temporary files and directories."
