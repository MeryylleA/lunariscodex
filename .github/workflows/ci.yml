# .github/workflows/ci.yml
name: Lunaris Codex CI

on:
  push:
    branches: [ main ]
    paths: # For pushes to main, run if core files change
      - 'model.py'
      - 'prepare_data.py'
      - 'train.py'
      - 'inference.py'
      - 'text_cleaner/**'
      - 'data_analyzer/**'
      - 'bpe_trainer/**' 
      - 'tests/**'
      - 'Makefile'
      - 'requirements.txt'
      - '.github/workflows/ci.yml'
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review] 
    branches: [ main ]
  workflow_dispatch: 

env:
  # Global environment variables
  CXXFLAGS_MODE: RELEASE
  PYTHON_VERSION: '3.11'

jobs:
  # ==============================================================================
  # CHANGE DETECTION & SETUP
  # ==============================================================================
  detect_changes:
    name: Detect Changes & Setup Matrix
    runs-on: ubuntu-latest
    outputs:
      cpp_changes: ${{ steps.cpp_changes.outputs.any_changed }}
      python_changes: ${{ steps.python_changes.outputs.any_changed }}
      should_run_cpp: ${{ steps.decision.outputs.should_run_cpp }}
      should_run_python: ${{ steps.decision.outputs.should_run_python }}
      test_matrix: ${{ steps.matrix.outputs.matrix }}
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Detect C++ related changes
      - name: Detect C++ Changes
        id: cpp_changes
        uses: tj-actions/changed-files@v46
        with:
          files: |
            Makefile
            text_cleaner/**
            data_analyzer/**
            bpe_trainer/**
            .github/workflows/ci.yml

      # Detect Python related changes
      - name: Detect Python Changes
        id: python_changes
        uses: tj-actions/changed-files@v46
        with:
          files: |
            model.py
            prepare_data.py
            train.py
            inference.py
            tests/**
            requirements.txt
            .github/workflows/ci.yml

      # Make execution decisions
      - name: Determine Job Execution
        id: decision
        run: |
          # C++ decision
          if [[ "${{ steps.cpp_changes.outputs.any_changed }}" == "true" || \
                "${{ github.event_name }}" == "push" || \
                "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "should_run_cpp=true" >> $GITHUB_OUTPUT
            echo "‚úÖ C++ jobs will run: Changes detected or triggered by push/manual dispatch"
          else
            echo "should_run_cpp=false" >> $GITHUB_OUTPUT
            echo "‚è≠Ô∏è C++ jobs will be skipped: No relevant changes detected"
          fi
          
          # Python decision
          if [[ "${{ steps.python_changes.outputs.any_changed }}" == "true" || \
                "${{ github.event_name }}" == "push" || \
                "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "should_run_python=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Python jobs will run: Changes detected or triggered by push/manual dispatch"
          else
            echo "should_run_python=false" >> $GITHUB_OUTPUT
            echo "‚è≠Ô∏è Python jobs will be skipped: No relevant changes detected"
          fi

      # Setup test matrix for cross-platform testing
      - name: Setup Test Matrix
        id: matrix
        run: |
          # Define OS matrix - focusing on Linux variants since you're unsure about Windows/macOS
          cat <<EOF > matrix.json
          {
            "os": [
              {
                "name": "ubuntu-latest",
                "display": "Ubuntu Latest",
                "runner": "ubuntu-latest",
                "shell": "bash"
              },
              {
                "name": "ubuntu-20.04",
                "display": "Ubuntu 20.04 LTS",
                "runner": "ubuntu-20.04", 
                "shell": "bash"
              }
            ]
          }
          EOF
          
          echo "matrix=$(cat matrix.json | jq -c .)" >> $GITHUB_OUTPUT
          echo "üîß Test matrix configured for cross-platform testing"

  # ==============================================================================
  # C++ UTILITIES BUILD & TEST (Multi-OS)
  # ==============================================================================
  cpp_utilities:
    name: C++ Build & Test (${{ matrix.os.display }})
    runs-on: ${{ matrix.os.runner }}
    needs: detect_changes
    if: needs.detect_changes.outputs.should_run_cpp == 'true'
    
    strategy:
      fail-fast: false # Continue testing other OS even if one fails
      matrix: ${{ fromJson(needs.detect_changes.outputs.test_matrix) }}
    
    outputs: 
      text_cleaner_exec: ${{ steps.executables.outputs.text_cleaner_exec }}
      data_analyzer_exec: ${{ steps.executables.outputs.data_analyzer_exec }}
      bpe_processor_exec: ${{ steps.executables.outputs.bpe_processor_exec }}

    steps:
      # --- Repository Setup ---
      - name: Checkout Repository
        uses: actions/checkout@v4

      # --- OS-specific Setup ---
      - name: Install Build Dependencies (Ubuntu)
        run: |
          echo "üîß Installing C++ build dependencies on ${{ matrix.os.display }}..."
          sudo apt-get update -y
          sudo apt-get install -y nlohmann-json3-dev build-essential
          
          # Show system info
          echo "üìä System Information:"
          uname -a
          gcc --version
          g++ --version

      # --- Build Cache Management ---
      - name: Cache C++ Executables
        id: cache_executables
        uses: actions/cache@v4
        with:
          path: | 
            text_cleaner/lunaris_text_cleaner
            data_analyzer/lunaris_data_analyzer
            bpe_trainer/bpe_processor 
          key: ${{ matrix.os.name }}-cpp-exec-${{ hashFiles('Makefile', 'text_cleaner/**/*.cpp', 'data_analyzer/**/*.cpp', 'bpe_trainer/**/*.cpp') }}
          restore-keys: |
            ${{ matrix.os.name }}-cpp-exec-

      # --- Build Process ---
      - name: Clean Previous Build Artifacts
        run: |
          echo "üßπ Cleaning previous build artifacts..."
          make clean || echo "‚ÑπÔ∏è No previous artifacts to clean"

      - name: Build C++ Utilities
        if: steps.cache_executables.outputs.cache-hit != 'true'
        run: |
          echo "üî® Building C++ utilities on ${{ matrix.os.display }}..."
          make all CXXFLAGS_MODE=${{ env.CXXFLAGS_MODE }}
          echo "‚úÖ C++ utilities built successfully"

      - name: Set Executable Paths
        id: executables
        run: |
          echo "text_cleaner_exec=text_cleaner/lunaris_text_cleaner" >> $GITHUB_OUTPUT
          echo "data_analyzer_exec=data_analyzer/lunaris_data_analyzer" >> $GITHUB_OUTPUT
          echo "bpe_processor_exec=bpe_trainer/bpe_processor" >> $GITHUB_OUTPUT
          
          if [[ "${{ steps.cache_executables.outputs.cache-hit }}" == "true" ]]; then
            echo "‚ôªÔ∏è C++ executables restored from cache"
          else
            echo "üÜï C++ executables built from source"
          fi

      # --- Functional Tests ---
      - name: Run Text Cleaner Tests
        run: |
          echo "üß™ Testing Text Cleaner utility on ${{ matrix.os.display }}..."
          
          # Setup test environment
          mkdir -p ./temp_text_cleaner_input ./temp_text_cleaner_output
          
          cat <<EOF > ./temp_text_cleaner_input/sample.txt
          <!DOCTYPE html>
          <html> <head><title>Test</title></head> <body>
          <!-- This is a comment -->
          <p>Hello   World!  </p>
          <script>alert("script content");</script>
          Another line.
          URL: http://example.com and email: test@example.com
          Duplicate Line
          Duplicate Line
          </body> </html>
          EOF

          # Run text cleaner
          TEXT_CLEANER_EXEC="./${{ steps.executables.outputs.text_cleaner_exec }}"
          if [ ! -f "$TEXT_CLEANER_EXEC" ]; then 
            echo "‚ùå ERROR: Text Cleaner executable not found at: $TEXT_CLEANER_EXEC"
            exit 1
          fi
          
          "$TEXT_CLEANER_EXEC" \
            --input ./temp_text_cleaner_input/sample.txt \
            --output ./temp_text_cleaner_output/cleaned.txt \
            --remove-html --normalize-whitespace --remove-empty-lines \
            --to-lowercase \
            --process-urls --url-placeholder "[url]" \
            --process-emails --email-placeholder "[email]" \
            --remove-exact-duplicates
          
          # Create expected output
          cat <<-EXPECTED_EOF > expected_output.txt
          test
          hello world!
          another line.
          url: [url] and email: [email]
          duplicate line
          EXPECTED_EOF
          
          # Verify output
          if diff -u expected_output.txt ./temp_text_cleaner_output/cleaned.txt; then
            echo "‚úÖ Text Cleaner test passed on ${{ matrix.os.display }}"
          else
            echo "‚ùå Text Cleaner test failed on ${{ matrix.os.display }}"
            exit 1
          fi

      - name: Run BPE Processor Tests
        run: |
          echo "üß™ Testing BPE Processor on ${{ matrix.os.display }}..."
          
          # Setup test environment
          mkdir -p ./temp_bpe/corpus ./temp_bpe/model_output
          
          cat <<EOF > ./temp_bpe/corpus/corpus.txt
          hello world this is a test a test
          another line for another test of the bpe
          hello world again
          EOF

          # Train BPE model
          BPE_EXEC="./${{ steps.executables.outputs.bpe_processor_exec }}"
          if [ ! -f "$BPE_EXEC" ]; then 
            echo "‚ùå ERROR: BPE Processor executable not found at: $BPE_EXEC"
            exit 1
          fi
          
          "$BPE_EXEC" \
            --action train \
            --corpus ./temp_bpe/corpus/corpus.txt \
            --vocab-size 270 \
            --output ./temp_bpe/model_output/bpe_model/ \
            --mode byte --verbose
            
          # Verify output files
          REQUIRED_FILES=(
            "./temp_bpe/model_output/bpe_model/bpe_model_lunaris.json"
            "./temp_bpe/model_output/bpe_model/merges_lunaris.txt"
            "./temp_bpe/model_output/bpe_model/vocabulary_lunaris.txt"
          )
          
          for file in "${REQUIRED_FILES[@]}"; do
            if [ ! -f "$file" ]; then
              echo "‚ùå ERROR: Required output file not found: $file"
              ls -R ./temp_bpe/model_output/
              exit 1
            fi
          done
          
          # Test tokenization
          TOKEN_OUTPUT=$("$BPE_EXEC" --action tokenize --model_path "./temp_bpe/model_output/bpe_model/" --input_text "hello test world" --verbose)
          
          if [ $? -ne 0 ] || [ -z "$TOKEN_OUTPUT" ]; then
            echo "‚ùå ERROR: BPE tokenization failed"
            exit 1
          fi
          
          echo "‚úÖ BPE Processor test passed on ${{ matrix.os.display }}"

      # --- Cleanup ---
      - name: Cleanup Test Files
        if: always()
        run: |
          echo "üßπ Cleaning up test files..."
          rm -rf ./temp_text_cleaner_input ./temp_text_cleaner_output \
                 ./expected_output.txt ./temp_bpe

  # ==============================================================================
  # PYTHON SUITE TESTS (Multi-OS)
  # ==============================================================================
  python_suite:
    name: Python Tests (${{ matrix.os.display }})
    runs-on: ${{ matrix.os.runner }}
    needs: detect_changes
    if: needs.detect_changes.outputs.should_run_python == 'true'
    
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.detect_changes.outputs.test_matrix) }}

    steps:
      # --- Repository Setup ---
      - name: Checkout Repository
        uses: actions/checkout@v4

      # --- Python Environment Setup ---
      - name: Setup Python Environment
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Display Python Info
        run: |
          echo "üêç Python Environment on ${{ matrix.os.display }}:"
          python --version
          pip --version
          echo "Platform: $(python -c 'import platform; print(platform.platform())')"

      - name: Cache Python Dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ matrix.os.name }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ matrix.os.name }}-pip-

      - name: Install Python Dependencies
        run: |
          echo "üì¶ Installing Python dependencies on ${{ matrix.os.display }}..."
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          echo "‚úÖ Dependencies installed successfully"

      # --- Unit Tests ---
      - name: Run Unit Tests
        run: |
          echo "üß™ Running unit tests on ${{ matrix.os.display }}..."
          export PYTHONPATH=$PYTHONPATH:$(pwd)
          pytest tests/ -k "test_model" \
            --cov=model \
            --cov-report=xml:coverage-${{ matrix.os.name }}.xml \
            --cov-report=term-missing \
            --tb=short
          echo "‚úÖ Unit tests completed on ${{ matrix.os.display }}"

      - name: Upload Coverage Report
        if: success()
        uses: codecov/codecov-action@v5 
        with:
          token: ${{ secrets.CODECOV_TOKEN }} 
          files: ./coverage-${{ matrix.os.name }}.xml
          flags: model-tests-${{ matrix.os.name }}
          name: codecov-${{ matrix.os.name }}

      # --- Integration Tests ---
      - name: Create Test Datasets
        run: |
          echo "üìù Creating test datasets on ${{ matrix.os.display }}..."
          
          # Training data
          mkdir -p ./temp_train_data
          echo "def train_function_one(): return 'train1'" > ./temp_train_data/train_sample_1.py
          echo "class TrainSampleClass:\n  value = 'train2'" > ./temp_train_data/train_sample_2.py
          
          # Validation data
          mkdir -p ./temp_val_data
          echo "def validation_function(): return 'validation_data_here'" > ./temp_val_data/val_sample_1.py
          echo "# Another validation line" > ./temp_val_data/val_sample_2.py
          
          echo "‚úÖ Test datasets created"

      - name: Test Data Preparation
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          echo "üîÑ Testing data preparation on ${{ matrix.os.display }}..."
          
          # Prepare training data
          python prepare_data.py \
            --data_source_type text_file_lines \
            --dataset_name_or_path "./temp_train_data/*.py" \
            --tokenizer_name_or_path gpt2 \
            --output_path ./processed_data/train_data.memmap \
            --max_length 32 --max_examples 2 --overwrite_output

          # Prepare validation data
          python prepare_data.py \
            --data_source_type text_file_lines \
            --dataset_name_or_path "./temp_val_data/*.py" \
            --tokenizer_name_or_path gpt2 \
            --output_path ./processed_data/val_data.memmap \
            --max_length 32 --max_examples 2 --overwrite_output
          
          echo "‚úÖ Data preparation completed on ${{ matrix.os.display }}"

      - name: Test Training Pipeline
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          echo "üèãÔ∏è Testing training pipeline on ${{ matrix.os.display }}..."
          python train.py \
            --memmap_file_train ./processed_data/train_data.memmap \
            --num_sequences_train 2 \
            --memmap_file_val ./processed_data/val_data.memmap \
            --num_sequences_val 2 \
            --tokenizer_name_or_path gpt2 \
            --dataset_max_length 32 --dataset_dtype int32 \
            --model_max_seq_len 32 --d_model 32 --n_layers 1 --n_heads 1 \
            --batch_size 1 --num_epochs 1 --device cpu \
            --checkpoint_dir ./checkpoints \
            --log_interval 1 --save_strategy epoch \
            --lora_rank 0 --seed 42
          echo "‚úÖ Training completed on ${{ matrix.os.display }}"

      - name: Test Inference Pipeline
        run: |
          echo "üîÆ Testing inference pipeline on ${{ matrix.os.display }}..."
          
          # Find the checkpoint file
          CHECKPOINT_PATH="./checkpoints/best_model.pt"
          if [ ! -f "$CHECKPOINT_PATH" ]; then 
            echo "‚ùå ERROR: Checkpoint file not found: $CHECKPOINT_PATH"
            ls -la ./checkpoints/
            exit 1
          fi
          
          # Run inference
          OUTPUT=$(python inference.py \
            --checkpoint_path "$CHECKPOINT_PATH" \
            --tokenizer_name_or_path gpt2 \
            --prompt "Test prompt:" \
            --max_new_tokens 5 \
            --temperature 0.5 \
            --device cpu --no_color)
          
          if [ $? -eq 0 ] && [ -n "$OUTPUT" ]; then
            echo "‚úÖ Inference test passed on ${{ matrix.os.display }}"
            echo "Generated output (first 100 chars): ${OUTPUT:0:100}..."
          else
            echo "‚ùå Inference test failed on ${{ matrix.os.display }}"
            exit 1
          fi

      # --- Cleanup ---
      - name: Cleanup Test Files
        if: always()
        run: |
          echo "üßπ Cleaning up test files..."
          rm -rf ./temp_train_data ./temp_val_data \
                 ./processed_data ./checkpoints \
                 ./coverage-${{ matrix.os.name }}.xml

  # ==============================================================================
  # FINAL STATUS REPORTING
  # ==============================================================================
  ci_status:
    name: CI Status Report
    runs-on: ubuntu-latest
    needs: [detect_changes, cpp_utilities, python_suite]
    if: always()
    
    steps:
      - name: Determine Overall Status
        id: status
        run: |
          CPP_STATUS="${{ needs.cpp_utilities.result }}"
          PYTHON_STATUS="${{ needs.python_suite.result }}"
          CPP_SHOULD_RUN="${{ needs.detect_changes.outputs.should_run_cpp }}"
          PYTHON_SHOULD_RUN="${{ needs.detect_changes.outputs.should_run_python }}"
          
          echo "üîç Job Status Summary:"
          echo "  - C++ Jobs: $CPP_STATUS (Should run: $CPP_SHOULD_RUN)"
          echo "  - Python Jobs: $PYTHON_STATUS (Should run: $PYTHON_SHOULD_RUN)"
          
          # Determine overall result
          OVERALL_SUCCESS=true
          
          if [[ "$CPP_SHOULD_RUN" == "true" && "$CPP_STATUS" != "success" ]]; then
            OVERALL_SUCCESS=false
            echo "‚ùå C++ jobs failed or were cancelled"
          fi
          
          if [[ "$PYTHON_SHOULD_RUN" == "true" && "$PYTHON_STATUS" != "success" ]]; then
            OVERALL_SUCCESS=false
            echo "‚ùå Python jobs failed or were cancelled"
          fi
          
          if [[ "$CPP_SHOULD_RUN" == "false" && "$PYTHON_SHOULD_RUN" == "false" ]]; then
            echo "‚è≠Ô∏è All jobs were skipped - no relevant changes detected"
            OVERALL_SUCCESS=true
          fi
          
          echo "overall_success=$OVERALL_SUCCESS" >> $GITHUB_OUTPUT
          
          if [[ "$OVERALL_SUCCESS" == "true" ]]; then
            echo "‚úÖ Overall CI Status: SUCCESS"
          else
            echo "‚ùå Overall CI Status: FAILURE"
          fi

      - name: Post Success Comment (PR)
        if: github.event_name == 'pull_request' && steps.status.outputs.overall_success == 'true'
        run: |
          read -r -d '' COMMENT_BODY <<EOF
          ---
          **Lunaris Codex CI Status: SUCCESS ‚úÖ** 
          Workflow: \`${{ github.workflow }}\`
          Branch: \`${{ github.head_ref }}\` (Commit: \`${{ github.sha }}\`)

          All tests passed successfully across multiple environments!
          üîó [View Action Details](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})

          *This is an automated message from your Lunaris Codex CI system.*
          EOF
          
          gh pr comment ${{ github.event.pull_request.number }} --body "$COMMENT_BODY" || echo "‚ö†Ô∏è Failed to post success comment"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Post Failure Comment (PR)
        if: github.event_name == 'pull_request' && steps.status.outputs.overall_success == 'false'
        run: |
          read -r -d '' COMMENT_BODY <<EOF
          ---
          **Lunaris Codex CI Status: FAILED ‚ùå** 
          Workflow: \`${{ github.workflow }}\`
          Branch: \`${{ github.head_ref }}\` (Commit: \`${{ github.sha }}\`)

          Some tests failed. Please review the logs and fix any issues.
          üîó [View Action Details](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})

          *This is an automated message from your Lunaris Codex CI system.*
          EOF
          
          gh pr comment ${{ github.event.pull_request.number }} --body "$COMMENT_BODY" || echo "‚ö†Ô∏è Failed to post failure comment"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Final Status Check
        run: |
          if [[ "${{ steps.status.outputs.overall_success }}" == "false" ]]; then
            echo "‚ùå CI Pipeline failed - exiting with error code"
            exit 1
          else
            echo "‚úÖ CI Pipeline completed successfully"
          fi
