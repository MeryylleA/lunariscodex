# .github/workflows/ci.yml
name: Lunaris Codex CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  test-pipeline:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache Python dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install Python dependencies
        run: |
          python -m venv .venv-ci
          source .venv-ci/bin/activate
          pip install --upgrade pip
          pip install -r requirements.txt
      
      # C++ build tools are generally available on ubuntu-latest runner

      - name: Create dummy datasets for CI
        run: |
          mkdir -p ./temp_data_ci_train
          echo "def train_function_one(): return 'train1'" > ./temp_data_ci_train/train_sample_1.py
          echo "class TrainSampleClass:\n  value = 'train2'" > ./temp_data_ci_train/train_sample_2.py
          mkdir -p ./temp_data_ci_val
          echo "def validation_function(): return 'validation_data_here'" > ./temp_data_ci_val/val_sample_1.py
          echo "# Another validation line" > ./temp_data_ci_val/val_sample_2.py

      - name: Run prepare_data.py for CI datasets
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          source .venv-ci/bin/activate
          echo "--- Preparing Training Data for CI ---"
          python prepare_data.py \
            --data_source_type text_file_lines \
            --dataset_name_or_path "./temp_data_ci_train/*.py" \
            --tokenizer_name_or_path gpt2 \
            --max_length 32 \
            --output_path ./processed_data_ci/ci_train_data.memmap \
            --max_examples 2

          echo "--- Preparing Validation Data for CI ---"
          python prepare_data.py \
            --data_source_type text_file_lines \
            --dataset_name_or_path "./temp_data_ci_val/*.py" \
            --tokenizer_name_or_path gpt2 \
            --max_length 32 \
            --output_path ./processed_data_ci/ci_val_data.memmap \
            --max_examples 2

      - name: Cache C++ build for Data Analyzer
        uses: actions/cache@v3
        with:
          path: ./data_analyzer/lda_ci_executable
          key: ${{ runner.os }}-data-analyzer-${{ hashFiles('data_analyzer/lunaris_data_analyzer.cpp') }}
          restore-keys: |
            ${{ runner.os }}-data-analyzer-

      - name: Build and Test C++ data analyzer
        run: |
          if [ ! -f ./data_analyzer/lda_ci_executable ]; then
            cd data_analyzer
            g++ lunaris_data_analyzer.cpp -o lda_ci_executable -std=c++17 || { echo "Compilation failed"; exit 1; }
            cd ..
          else
            echo "Using cached data_analyzer executable"
          fi
          
          DATA_ANALYZER_CMD="./data_analyzer/lda_ci_executable \
            --file ./processed_data_ci/ci_train_data.memmap \
            --num_sequences 2 \
            --max_length 32 \
            --dtype int32 \
            --print_seq 1 \
            --top_n_tokens 3"
          
          echo "Executing command: $DATA_ANALYZER_CMD"
          eval $DATA_ANALYZER_CMD || { echo "Analyzer execution failed"; exit 1; }

      - name: Run train.py (toy model with validation)
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          source .venv-ci/bin/activate
          python train.py \
            --memmap_file_train ./processed_data_ci/ci_train_data.memmap \
            --num_sequences_train 2 \
            --memmap_file_val ./processed_data_ci/ci_val_data.memmap \
            --num_sequences_val 2 \
            --tokenizer_name_or_path gpt2 \
            --dataset_max_length 32 \
            --dataset_dtype int32 \
            --model_max_seq_len 32 \
            --d_model 32 \
            --n_layers 1 \
            --n_heads 1 \
            --batch_size 1 \
            --num_epochs 1 \
            --device cpu \
            --checkpoint_dir ./checkpoints_ci \
            --log_interval 1 \
            --save_strategy epoch \
            --lora_rank 0 \
            --seed 42

      - name: Check for checkpoint files
        run: |
          echo "Listing contents of checkpoint directory: ./checkpoints_ci"
          ls -R ./checkpoints_ci
          
          MAIN_CKPT_FILE="./checkpoints_ci/lunaris_codex_epoch-1_step-2.pt"
          BEST_MODEL_FILE="./checkpoints_ci/best_model.pt"

          if [ ! -f "$MAIN_CKPT_FILE" ]; then
            echo "ERROR: Main checkpoint file '$MAIN_CKPT_FILE' not found!"
            exit 1
          else
            echo "Main checkpoint file '$MAIN_CKPT_FILE' found."
          fi

          if [ ! -f "$BEST_MODEL_FILE" ]; then
            echo "ERROR: 'best_model.pt' not found! Expected with validation and save_strategy=epoch."
            exit 1
          else
            echo "'best_model.pt' found."
          fi
          echo "All expected checkpoint files found. CI test successful."

      - name: Clean up
        if: always()
        run: |
          rm -rf .venv-ci ./temp_data_ci_train ./temp_data_ci_val ./processed_data_ci ./checkpoints_ci ./data_analyzer/lda_ci_executable
          echo "Cleaned up temporary files and directories."
