# .github/workflows/ci.yml
name: Lunaris Codex CI

on:
  push:
    branches: [ main ]
    paths:
      - 'model.py'
      - 'prepare_data.py'
      - 'train.py'
      - 'inference.py'
      - 'text_cleaner/**'
      - 'data_analyzer/**'
      - 'bpe_trainer/**'
      - 'tests/**'
      - 'Makefile'
      - 'requirements.txt'
      - '.github/workflows/ci.yml'
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]
    branches: [ main ]
  workflow_dispatch:

env:
  CXXFLAGS_MODE: RELEASE
  PYTHON_VERSION: '3.11'
  PYTHONUTF8: "1"

jobs:
  detect_changes:
    name: Detect Changes & Setup Matrix
    runs-on: ubuntu-latest
    outputs:
      cpp_changes: ${{ steps.cpp_changes.outputs.any_changed }}
      python_changes: ${{ steps.python_changes.outputs.any_changed }}
      should_run_cpp: ${{ steps.decision.outputs.should_run_cpp }}
      should_run_python: ${{ steps.decision.outputs.should_run_python }}
      test_matrix: ${{ steps.matrix.outputs.matrix }}

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Detect C++ Changes
        id: cpp_changes
        uses: tj-actions/changed-files@v46
        with:
          files: |
            Makefile
            text_cleaner/**
            data_analyzer/**
            bpe_trainer/**
            .github/workflows/ci.yml

      - name: Detect Python Changes
        id: python_changes
        uses: tj-actions/changed-files@v46
        with:
          files: |
            model.py
            prepare_data.py
            train.py
            inference.py
            tests/**
            requirements.txt
            .github/workflows/ci.yml

      - name: Determine Job Execution
        id: decision
        run: |
          if [[ "${{ steps.cpp_changes.outputs.any_changed }}" == "true" || \
                "${{ github.event_name }}" == "push" || \
                "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "should_run_cpp=true" >> $GITHUB_OUTPUT
          else
            echo "should_run_cpp=false" >> $GITHUB_OUTPUT
          fi
          if [[ "${{ steps.python_changes.outputs.any_changed }}" == "true" || \
                "${{ github.event_name }}" == "push" || \
                "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "should_run_python=true" >> $GITHUB_OUTPUT
          else
            echo "should_run_python=false" >> $GITHUB_OUTPUT
          fi

      - name: Setup Test Matrix
        id: matrix
        run: |
          cat <<EOF > matrix.json
          {
            "os": [
              {
                "name": "ubuntu-latest", 
                "display": "Ubuntu Latest (24.04)",
                "runner": "ubuntu-latest"
              },
              {
                "name": "ubuntu-22.04",
                "display": "Ubuntu 22.04 LTS",
                "runner": "ubuntu-22.04"
              }
            ]
          }
          EOF
          echo "matrix=$(cat matrix.json | jq -c .)" >> $GITHUB_OUTPUT

  cpp_utilities:
    name: C++ Build & Test (${{ matrix.os.display }})
    runs-on: ${{ matrix.os.runner }}
    needs: detect_changes
    if: needs.detect_changes.outputs.should_run_cpp == 'true'
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.detect_changes.outputs.test_matrix) }}
    defaults:
      run:
        shell: bash
    outputs:
      text_cleaner_exec_path: ${{ steps.executables.outputs.text_cleaner_exec }}
      data_analyzer_exec_path: ${{ steps.executables.outputs.data_analyzer_exec }}
      bpe_processor_exec_path: ${{ steps.executables.outputs.bpe_processor_exec }}

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Install Build Dependencies (Ubuntu)
        run: |
          sudo apt-get update -y
          sudo apt-get install -y nlohmann-json3-dev build-essential
          g++ --version

      - name: Cache C++ Executables
        id: cache_executables
        uses: actions/cache@v4
        with:
          path: |
            ${{ github.workspace }}/text_cleaner/lunaris_text_cleaner
            ${{ github.workspace }}/data_analyzer/lunaris_data_analyzer
            ${{ github.workspace }}/bpe_trainer/bpe_processor
          # Chave mais espec√≠fica para o cache, incluindo hashes de arquivos fonte e Makefile
          key: ${{ matrix.os.runner }}-cpp-exec-v1-${{ hashFiles('Makefile', 'text_cleaner/**/*.cpp', 'text_cleaner/**/*.hpp', 'data_analyzer/**/*.cpp', 'data_analyzer/**/*.hpp', 'bpe_trainer/**/*.cpp', 'bpe_trainer/**/*.hpp') }}
          restore-keys: |
            ${{ matrix.os.runner }}-cpp-exec-v1-

      - name: Clean Previous Build Artifacts
        # Roda mesmo se o cache for restaurado, para garantir um ambiente limpo para o build (se necess√°rio)
        # Mas o build s√≥ roda se n√£o houver cache hit.
        run: |
          make clean || echo "‚ÑπÔ∏è Clean failed or no artifacts to clean."

      - name: Build C++ Utilities
        if: steps.cache_executables.outputs.cache-hit != 'true'
        run: |
          echo "üî® Building C++ utilities (cache miss)..."
          make all CXXFLAGS_MODE=${{ env.CXXFLAGS_MODE }}
          echo "‚úÖ C++ utilities built successfully."
      - name: List files after potential build/cache restore
        run: |
          echo "üìÇ Listing workspace after build/cache restore:"
          ls -lA ${{ github.workspace }}/
          echo "üìÇ Listing text_cleaner/:"
          ls -lA ${{ github.workspace }}/text_cleaner/ || true
          echo "üìÇ Listing data_analyzer/:"
          ls -lA ${{ github.workspace }}/data_analyzer/ || true
          echo "üìÇ Listing bpe_trainer/:"
          ls -lA ${{ github.workspace }}/bpe_trainer/ || true

      - name: Set and Verify Executable Paths
        id: executables
        run: |
          TC_EXEC="${{ github.workspace }}/text_cleaner/lunaris_text_cleaner"
          DA_EXEC="${{ github.workspace }}/data_analyzer/lunaris_data_analyzer"
          BPE_EXEC="${{ github.workspace }}/bpe_trainer/bpe_processor"

          echo "text_cleaner_exec=$TC_EXEC" >> $GITHUB_OUTPUT
          echo "data_analyzer_exec=$DA_EXEC" >> $GITHUB_OUTPUT
          echo "bpe_processor_exec=$BPE_EXEC" >> $GITHUB_OUTPUT

          if [[ "${{ steps.cache_executables.outputs.cache-hit }}" == "true" ]]; then
            echo "‚ôªÔ∏è Cache hit reported. Verifying cached executables..."
          else
            echo "üÜï No cache hit / executables built from source. Verifying built executables..."
          fi

          # Verificar se os arquivos existem e s√£o execut√°veis
          all_execs_found=true
          for exec_file in "$TC_EXEC" "$DA_EXEC" "$BPE_EXEC"; do
            if [ ! -f "$exec_file" ]; then
              echo "‚ùå ERROR: Executable not found: $exec_file"
              all_execs_found=false
            elif [ ! -x "$exec_file" ]; then
              echo "‚ùå ERROR: File found but not executable: $exec_file"
              ls -l "$exec_file" # Mostra permiss√µes
              all_execs_found=false
            else
              echo "‚úÖ Found executable: $exec_file"
              ls -l "$exec_file"
            fi
          done

          if [[ "$all_execs_found" != "true" ]]; then
            echo "üî• At least one executable was not found or not executable. Failing step."
            echo "Listing relevant directories for debugging:"
            echo "--- text_cleaner directory ---"
            ls -lA ${{ github.workspace }}/text_cleaner/
            echo "--- data_analyzer directory ---"
            ls -lA ${{ github.workspace }}/data_analyzer/
            echo "--- bpe_trainer directory ---"
            ls -lA ${{ github.workspace }}/bpe_trainer/
            exit 1
          fi
          echo "All executables verified successfully."

    # --- Test Steps (iguais aos anteriores, usando os outputs de 'executables') ---
      - name: Run Text Cleaner Tests
        run: |
          echo "üß™ Testing Text Cleaner utility on ${{ matrix.os.display }}..."
          TEXT_CLEANER_EXEC="${{ steps.executables.outputs.text_cleaner_exec_path }}"
          
          # A verifica√ß√£o de exist√™ncia j√° foi feita na etapa anterior
          # if [ ! -f "$TEXT_CLEANER_EXEC" ]; then ... exit 1; fi

          mkdir -p ./temp_text_cleaner_input ./temp_text_cleaner_output
          cat <<EOF > ./temp_text_cleaner_input/sample.txt
          <!DOCTYPE html>
          <html> <head><title>Test</title></head> <body>
          <!-- This is a comment -->
          <p>Hello   World!  </p>
          <script>alert("script content");</script>
          Another line.
          URL: http://example.com and email: test@example.com
          Duplicate Line
          Duplicate Line
          </body> </html>
          EOF

          "$TEXT_CLEANER_EXEC" \
            --input ./temp_text_cleaner_input/sample.txt \
            --output ./temp_text_cleaner_output/cleaned.txt \
            --remove-html --normalize-whitespace --remove-empty-lines \
            --to-lowercase \
            --process-urls --url-placeholder "[url]" \
            --process-emails --email-placeholder "[email]" \
            --remove-exact-duplicates

          cat <<-EXPECTED_EOF > expected_output.txt
          test
          hello world!
          another line.
          url: [url] and email: [email]
          duplicate line
          EXPECTED_EOF

          if diff -u expected_output.txt ./temp_text_cleaner_output/cleaned.txt; then
            echo "‚úÖ Text Cleaner test passed on ${{ matrix.os.display }}"
          else
            echo "‚ùå Text Cleaner test failed on ${{ matrix.os.display }}"
            echo "--- Expected ---"
            cat expected_output.txt
            echo "--- Actual ---"
            cat ./temp_text_cleaner_output/cleaned.txt
            exit 1
          fi

      - name: Run BPE Processor Tests
        run: |
          echo "üß™ Testing BPE Processor on ${{ matrix.os.display }}..."
          BPE_EXEC="${{ steps.executables.outputs.bpe_processor_exec_path }}"
          
          mkdir -p ./temp_bpe/corpus ./temp_bpe/model_output
          cat <<EOF > ./temp_bpe/corpus/corpus.txt
          hello world this is a test a test
          another line for another test of the bpe
          hello world again
          EOF

          "$BPE_EXEC" \
            --action train \
            --corpus ./temp_bpe/corpus/corpus.txt \
            --vocab-size 270 \
            --output ./temp_bpe/model_output/bpe_model/ \
            --mode byte --verbose

          REQUIRED_FILES=(
            "./temp_bpe/model_output/bpe_model/bpe_model_lunaris.json"
            "./temp_bpe/model_output/bpe_model/merges_lunaris.txt"
            "./temp_bpe/model_output/bpe_model/vocabulary_lunaris.txt"
          )
          for file in "${REQUIRED_FILES[@]}"; do
            if [ ! -f "$file" ]; then
              echo "‚ùå ERROR: Required output file not found: $file"
              ls -R ./temp_bpe/model_output/
              exit 1
            fi
          done
          
          TOKEN_OUTPUT=$("$BPE_EXEC" --action tokenize --model_path "./temp_bpe/model_output/bpe_model/" --input_text "hello test world" --verbose)
          if [ $? -ne 0 ] || [ -z "$TOKEN_OUTPUT" ]; then
            echo "‚ùå ERROR: BPE tokenization failed. Output: $TOKEN_OUTPUT"
            exit 1
          fi
          echo "‚úÖ BPE Processor test passed on ${{ matrix.os.display }}"

      - name: Cleanup Test Files
        if: always()
        run: |
          rm -rf ./temp_text_cleaner_input ./temp_text_cleaner_output ./expected_output.txt ./temp_bpe
  
  # ... (python_suite e ci_status permanecem os mesmos da sua √∫ltima vers√£o)
  python_suite:
    name: Python Tests (${{ matrix.os.display }})
    runs-on: ${{ matrix.os.runner }}
    needs: detect_changes
    if: needs.detect_changes.outputs.should_run_python == 'true'
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.detect_changes.outputs.test_matrix) }}
    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Python Environment
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Display Python Info
        run: |
          python --version
          pip --version

      - name: Cache Python Dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ matrix.os.runner }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ matrix.os.runner }}-pip-

      - name: Install Python Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Unit Tests
        run: |
          echo "üß™ Running unit tests on ${{ matrix.os.display }}..."
          python -m pytest tests/ -k "test_model" \
            --cov=model \
            --cov-report=xml:coverage-${{ matrix.os.name }}.xml \
            --cov-report=term-missing \
            --tb=short
          echo "‚úÖ Unit tests completed on ${{ matrix.os.display }}"

      - name: Upload Coverage Report
        if: success() && matrix.os.name == 'ubuntu-latest' 
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage-${{ matrix.os.name }}.xml
          flags: model-tests-${{ matrix.os.name }}
          name: codecov-ubuntu-latest
          fail_ci_if_error: true

      - name: Create Test Datasets
        run: |
          mkdir -p ./temp_train_data ./temp_val_data
          echo "def train_function_one(): return 'train1'" > ./temp_train_data/train_sample_1.py
          echo "class TrainSampleClass:\n  value = 'train2'" > ./temp_train_data/train_sample_2.py
          echo "def validation_function(): return 'validation_data_here'" > ./temp_val_data/val_sample_1.py
          echo "# Another validation line" > ./temp_val_data/val_sample_2.py

      - name: Test Data Preparation
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          python prepare_data.py \
            --data_source_type text_file_lines \
            --dataset_name_or_path "./temp_train_data/*.py" \
            --tokenizer_name_or_path gpt2 \
            --output_path ./processed_data/train_data.memmap \
            --max_length 32 --max_examples 2 --overwrite_output
          python prepare_data.py \
            --data_source_type text_file_lines \
            --dataset_name_or_path "./temp_val_data/*.py" \
            --tokenizer_name_or_path gpt2 \
            --output_path ./processed_data/val_data.memmap \
            --max_length 32 --max_examples 2 --overwrite_output

      - name: Test Training Pipeline
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          python train.py \
            --memmap_file_train ./processed_data/train_data.memmap \
            --num_sequences_train 2 \
            --memmap_file_val ./processed_data/val_data.memmap \
            --num_sequences_val 2 \
            --tokenizer_name_or_path gpt2 \
            --dataset_max_length 32 --dataset_dtype int32 \
            --model_max_seq_len 32 --d_model 32 --n_layers 1 --n_heads 1 \
            --batch_size 1 --num_epochs 1 --device cpu \
            --checkpoint_dir ./checkpoints \
            --log_interval 1 --save_strategy epoch \
            --lora_rank 0 --seed 42

      - name: Test Inference Pipeline
        run: |
          CHECKPOINT_PATH="./checkpoints/best_model.pt"
          if [ ! -f "$CHECKPOINT_PATH" ]; then
            ls -la ./checkpoints/
            exit 1
          fi
          OUTPUT=$(python inference.py \
            --checkpoint_path "$CHECKPOINT_PATH" \
            --tokenizer_name_or_path gpt2 \
            --prompt "Test prompt:" \
            --max_new_tokens 5 \
            --temperature 0.5 \
            --device cpu --no_color)
          if [ $? -eq 0 ] && [ -n "$OUTPUT" ]; then
            echo "Generated output (first 100 chars): ${OUTPUT:0:100}..."
          else
            echo "‚ùå Inference test failed"
            exit 1
          fi

      - name: Cleanup Test Files
        if: always()
        run: |
          rm -rf ./temp_train_data ./temp_val_data ./processed_data ./checkpoints ./coverage-${{ matrix.os.name }}.xml

  ci_status:
    name: CI Status Report
    runs-on: ubuntu-latest
    needs: [detect_changes, cpp_utilities, python_suite]
    if: always()
    steps:
      - name: Determine Overall Status
        id: status
        shell: bash
        run: |
          CPP_JOB_EXISTS="${{ needs.detect_changes.outputs.should_run_cpp }}"
          PYTHON_JOB_EXISTS="${{ needs.detect_changes.outputs.should_run_python }}"
          CPP_STATUS="skipped" 
          if [[ "$CPP_JOB_EXISTS" == "true" ]]; then
            CPP_STATUS="${{ needs.cpp_utilities.result || 'failure' }}" 
          fi
          PYTHON_STATUS="skipped"
          if [[ "$PYTHON_JOB_EXISTS" == "true" ]]; then
            PYTHON_STATUS="${{ needs.python_suite.result || 'failure' }}"
          fi
          echo "üîç Job Status Summary:"
          echo "  - C++ Jobs (Should Run: $CPP_JOB_EXISTS): $CPP_STATUS"
          echo "  - Python Jobs (Should Run: $PYTHON_JOB_EXISTS): $PYTHON_STATUS"
          OVERALL_SUCCESS="true"
          if [[ "$CPP_JOB_EXISTS" == "true" && "$CPP_STATUS" != "success" && "$CPP_STATUS" != "skipped" ]]; then
            OVERALL_SUCCESS="false"
          fi
          if [[ "$PYTHON_JOB_EXISTS" == "true" && "$PYTHON_STATUS" != "success" && "$PYTHON_STATUS" != "skipped" ]]; then
            OVERALL_SUCCESS="false"
          fi
          if [[ "$CPP_JOB_EXISTS" == "false" && "$PYTHON_JOB_EXISTS" == "false" ]]; then
            OVERALL_SUCCESS="true" 
          fi
          echo "overall_success=$OVERALL_SUCCESS" >> "$GITHUB_OUTPUT"
          if [[ "$OVERALL_SUCCESS" == "true" ]]; then
            echo "‚úÖ Overall CI Status: SUCCESS"
          else
            echo "‚ùå Overall CI Status: FAILURE"
          fi

      - name: Post Comment (PR)
        if: github.event_name == 'pull_request'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GH_REPO: ${{ github.repository }}
        run: |
          STATUS_ICON="‚úÖ"
          STATUS_TEXT="SUCCESS"
          if [[ "${{ steps.status.outputs.overall_success }}" == "false" ]]; then
            STATUS_ICON="‚ùå"
            STATUS_TEXT="FAILED"
          fi
          COMMENT_BODY="---
          **Lunaris Codex CI Status (Ubuntu Only): $STATUS_TEXT $STATUS_ICON** 
          Workflow: \`${{ github.workflow }}\`
          Branch: \`${{ github.head_ref }}\` (Commit: \`${{ github.sha }}\`)
          üîó [View Action Details](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
          *This is an automated message.*"
          gh pr comment ${{ github.event.pull_request.number }} --body "$COMMENT_BODY" || echo "‚ö†Ô∏è Failed to post comment (ensure GITHUB_TOKEN has 'pull-requests: write' permission or it's a PR event)."

      - name: Final Status Check
        shell: bash
        run: |
          if [[ "${{ steps.status.outputs.overall_success }}" == "false" ]]; then
            echo "‚ùå CI Pipeline failed - exiting with error code"
            exit 1
          else
            echo "‚úÖ CI Pipeline completed successfully"
          fi
