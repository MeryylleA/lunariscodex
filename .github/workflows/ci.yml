# .github/workflows/ci.yml
name: Lunaris Codex CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  test-pipeline:
    name: Test Python Pipeline and C++ Utilities
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Python dependencies
        run: |
          python -m venv .venv-ci
          source .venv-ci/bin/activate
          pip install --upgrade pip
          pip install -r requirements.txt
      
      # C++ build tools (g++) are generally available on ubuntu-latest runner.

      - name: Create dummy datasets for CI
        run: |
          echo "Creating dummy text files for CI tests..."
          mkdir -p ./temp_data_ci_raw # For text_cleaner input
          mkdir -p ./temp_data_ci_train # For prepare_data input (after cleaning)
          mkdir -p ./temp_data_ci_val   # For prepare_data input (after cleaning)

          echo "   Line with too many    spaces and MiXeD CaSe. URL: http://example.com/test" > ./temp_data_ci_raw/raw_file1.txt
          echo "contact_me@example.org for details" >> ./temp_data_ci_raw/raw_file1.txt
          echo "" >> ./temp_data_ci_raw/raw_file1.txt # Empty line
          echo "Duplicate line to be cleaned." >> ./temp_data_ci_raw/raw_file1.txt
          echo "Duplicate line to be cleaned." >> ./temp_data_ci_raw/raw_file1.txt
          
          echo "Another file for training." > ./temp_data_ci_raw/raw_file2.log # Different extension
          
          # Create files that will be "cleaned" and then used by prepare_data
          cp ./temp_data_ci_raw/raw_file1.txt ./temp_data_ci_train/train_sample_1.txt # Will be cleaned by text_cleaner first
          cp ./temp_data_ci_raw/raw_file2.log ./temp_data_ci_train/train_sample_2.log # Will be cleaned
          
          echo "def validation_function(): return 'validation_data_here'" > ./temp_data_ci_val/val_sample_1.py
          echo "# Another validation line for diversity" > ./temp_data_ci_val/val_sample_2.py
          echo "Done creating dummy files."

      - name: Build and Run C++ Text Cleaner
        run: |
          echo "--- Building and Running lunaris_text_cleaner ---"
          (cd text_cleaner && g++ lunaris_text_cleaner.cpp -o ltc_ci_executable -std=c++17)
          
          # Define o comando em uma variável para facilitar o echo e a execução
          CLEANER_CMD="./text_cleaner/ltc_ci_executable \
            --input ./temp_data_ci_raw \
            --output ./temp_data_ci_train \
            --input-pattern \"*\" \
            --recursive \
            --normalize-whitespace \
            --to-lowercase \
            --remove-empty-lines \
            --process-urls --url-placeholder \"[URL]\" \
            --process-emails --email-placeholder \"[EMAIL]\" \
            --remove-exact-duplicates"
          
          echo "Executing command: $CLEANER_CMD"
          eval $CLEANER_CMD
          
          echo "Contents of temp_data_ci_train after cleaning:"
          ls -R ./temp_data_ci_train

      - name: Run prepare_data.py for CI datasets
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }} # In case tokenizer needs it
        run: |
          source .venv-ci/bin/activate
          echo "--- Preparing Training Data (from cleaned files) for CI ---"
          python prepare_data.py \
            --data_source_type text_file_lines \
            --dataset_name_or_path "./temp_data_ci_train/*" \
            --tokenizer_name_or_path gpt2 \
            --max_length 32 \
            --output_path ./processed_data_ci/ci_train_data.memmap \
            --max_examples 10

          echo "--- Preparing Validation Data (raw) for CI ---"
          python prepare_data.py \
            --data_source_type text_file_lines \
            --dataset_name_or_path "./temp_data_ci_val/*.py" \
            --tokenizer_name_or_path gpt2 \
            --max_length 32 \
            --output_path ./processed_data_ci/ci_val_data.memmap \
            --max_examples 2
            
      - name: Build and Run C++ Data Analyzer
        run: |
          echo "--- Building and Running lunaris_data_analyzer ---"
          # Build the analyzer in the data_analyzer directory
          cd data_analyzer && g++ lunaris_data_analyzer.cpp -o lda_ci_executable -std=c++17 -g || { echo "Compilation failed"; exit 1; }
          cd ..
          
          # Execute the analyzer with the correct path
          ./data_analyzer/lda_ci_executable \
            --file ./processed_data_ci/ci_train_data.memmap \
            --num_sequences 2 \
            --max_length 32 \
            --dtype int32 \
            --print_seq 1 \
            --top_n_tokens 3 || { echo "Analyzer execution failed"; exit 1; }

      - name: Run train.py (toy model with validation)
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }} # In case tokenizer in train.py needs it
        run: |
          source .venv-ci/bin/activate
          python train.py \
            --memmap_file_train ./processed_data_ci/ci_train_data.memmap \
            --num_sequences_train 2 \
            --memmap_file_val ./processed_data_ci/ci_val_data.memmap \
            --num_sequences_val 2 \
            --tokenizer_name_or_path gpt2 \
            --dataset_max_length 32 \
            --dataset_dtype int32 \
            --model_max_seq_len 32 \
            --d_model 32 \
            --n_layers 1 \
            --n_heads 1 \
            --batch_size 1 \
            --num_epochs 1 \
            --device cpu \
            --checkpoint_dir ./checkpoints_ci \
            --log_interval 1 \
            --save_strategy epoch \
            --lora_rank 0 \
            --seed 42

      - name: Check for checkpoint files
        run: |
          echo "Listing contents of checkpoint directory: ./checkpoints_ci"
          ls -R ./checkpoints_ci
          
          # Based on num_sequences_train = 2 and batch_size = 1, global_step will be 2.
          MAIN_CKPT_FILE="./checkpoints_ci/lunaris_codex_epoch-1_step-2.pt"
          BEST_MODEL_FILE="./checkpoints_ci/best_model.pt"

          if [ ! -f "$MAIN_CKPT_FILE" ]; then
            echo "ERROR: Main checkpoint file '$MAIN_CKPT_FILE' not found!"
            exit 1
          else
            echo "Main checkpoint file '$MAIN_CKPT_FILE' found."
          fi

          if [ ! -f "$BEST_MODEL_FILE" ]; then
            echo "ERROR: 'best_model.pt' not found! Expected with validation and save_strategy=epoch."
            exit 1
          else
            echo "'best_model.pt' found."
          fi
          echo "All expected checkpoint files found. CI test successful."
